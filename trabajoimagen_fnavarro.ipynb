{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análisis de datos no estructurados: Análisis de Imágenes\n",
    "\n",
    "### Autor: Felipe David Navarro Pecci\n",
    "\n",
    "## Descripción:\n",
    "\n",
    "En esta práctica se va a desarrollar un clasificador de imágenes para detectar si en dichas imágenes las personas están llevando mascarilla o no.\n",
    "\n",
    "Para ello se va trabajar con la API de detección de objetos de Tensorflow:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup\n",
    "\n",
    "En primer lugar, hay que preparar el entorno de trabajo con las librerías y configuración adecuados.\n",
    "\n",
    "Para ello, se sigue esta guía:\n",
    "\n",
    "https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/install.html#set-env\n",
    "\n",
    "NOTA: Si se trabaja en una máquina con GPU(s) es necesario tener instalado CUDA\n",
    "\n",
    "+ CUDA Toolkit v10.1\n",
    "+ CuDNN 7.6.5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workflow\n",
    "\n",
    "Para el desarrollo de este proyecto se va a seguir el siguiente procedimiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import de paquetes y librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## General\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Limpieza de datos\n",
    "import os\n",
    "import xml.etree.ElementTree as et\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Trabajo con imágenes\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import VGG16\n",
    "import cv2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga y limpieza de datos\n",
    "\n",
    "Se va a trabajar con el siguiente dataset, obtenido de Kaggle: https://makeml.app/datasets/mask\n",
    "\n",
    "Este dataset contiene 853 imágenes, pertenecientes a 3 clases:\n",
    "\n",
    "+ Con mascarilla\n",
    "+ Sin mascarilla\n",
    "+ Con mascarilla llevada incorrectamente\n",
    "\n",
    "\n",
    "Las imágenes vienen en formato PASCAL VOC. Cada imagen está por tanto definida por la imagen en sí y un fichero de anotaciones en formato xml que define las propiedades de dicha imagen.\n",
    "\n",
    "Cabe señalar que hay algunas imágenes que contienen más de una persona y por tanto hay varios objetos definidos en el xml de esas imágenes.\n",
    "\n",
    "Las imágenes ya vienen anotadas, por lo que no es necesario hacer dicha anotación a mano. \n",
    "Si fuera necesario, se puede utilizar la librería labelImg (https://github.com/tzutalin/labelImg#usage), que proporciona un GUI para anotar las imágenes y permite guardar las anotaciones en formato PASCAL VOC o YOLO.\n",
    "\n",
    "El siguiente paso es separar las imágenes junto con sus xmls en un conjunto de entrenamiento y un conjunto de test. (90/10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio_test = 0.1  ## Ratio de imágenes de test\n",
    "\n",
    "img_source =\n",
    "labels_source = \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizar una imagen de ejemplo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crear Label Map\n",
    "\n",
    "Creamos un label map, que mapea los labels utilizados a un valor entero.\n",
    "\n",
    "Este fichero se guarda en la misma carpeta que las anotaciones y tiene extensión .pbtxt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item {\n",
    "    id: 1\n",
    "    name: 'without_mask'\n",
    "}\n",
    "\n",
    "item {\n",
    "    id: 2\n",
    "    name: 'with_mask'\n",
    "}\n",
    "\n",
    "item {\n",
    "    id: \n",
    "    name: 'mask_weared_incorrect'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generar TFrecords a partir de las imágenes y los xmls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descarga de modelo pre-entrenado\n",
    "\n",
    "Se va a utilizar transfer learning, pues entrenar un modelo de detección de objetos desde 0 es muy costoso y no se dispone de un número muy elevado de imágenes.\n",
    "\n",
    "Para ello se descarga el modelo desde \"Tensorflow 2 Detection Model Zoo\"  \n",
    "(https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuración del entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprobación de número de GPUs disponibles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Métricas Entrenamiento vs. Validación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicción con una foto fuera del dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tecnologias]",
   "language": "python",
   "name": "conda-env-tecnologias-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
